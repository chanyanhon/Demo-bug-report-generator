# Demo-bug-report-generator
Demo to compare bug reports generated by LLM or from scratch

# Introduction

This is a general demonstration of how we can aid the beginners to create bug reports by simply inputting ONLY 4 parameters, i.e. 2 pairs of request-response for normal-browsing, and that of successfully hacked.

The LLM can compare the difference and find out the hacking logic behind, i.e. how the hacker successfully exploited the vulnerability, thus returning details of the reports including `summary`, `step to reproduce` and `recommendation to fix this vulnerability`

## Impact
- With this tool, by interview, the beginners said they have saved 1 hour for producing one bug report and agree that they are more attached to our platform because of having this helping tool.

- They also said that the tool helped them to write a better report other than saving time:
    - More Structural (Best practice format: summary, step of reproduction, recommendation), especially most of the beginners usually write too detailed or too brief for step of reproduce
    - Superior knowledge (Most of the time, inexperienced hackers cannot give recommendations)
    - More professional (No grammatical mistakes)
    - Generated in 2 seconds instead of 60 minutes

## Technical details
- We will apply `gemini-pro` model from Google as most of our input exceeds `gpt-3.5-turbo` maximum token limit (4,096 tokens), while Gemini-Pro can ingest 32,000 tokens for input.

- For generating a prompt template of `generating bug report in your custom style` with input variables of parameters (2 pairs of request-response in this case), please read the steps from my Medium article 

`Generating a report in a tailored format using Reverse Prompt Engineering` : 
https://medium.com/@miltonchan_85581/generating-a-report-in-a-tailored-format-using-reverse-prompt-engineering-16d1944a6413

# Further optimization
### User Feedback

In real-time endpoint serving, users may report that the latency (waiting time) will be too long as the LLM may process for a few seconds, while the UI shows no response before the LLM completes processing, i.e. output __all the texts__.

### Solution
The Latency may lead to users dropping out. To fix this, we can adopt a streaming property which outputs the texts in chunks so the users can see the progress of loading and they will be more willing to wait.


### Technical details
By Setting ```stream=True```, LLM will output the texts in chunks

``` python
response = model.generate_content(bugreport_prompt ,
                  generation_config=genai.types.GenerationConfig(temperature=0),
                  safety_settings=safety_settings,
                  stream=True  # output text in chunks 
                 )
for response in responses:
    print(response.text, end="")
```

### Example 1
Before tools

![Screenshot of a comment on a GitHub issue showing an image, added in the Markdown, of an Octocat smiling and raising a tentacle.](https://github.com/chanyanhon/Demo-bug-report-generator/blob/main/screencap/eg1_pre.png?raw=true)

After tools

![Screenshot of a comment on a GitHub issue showing an image, added in the Markdown, of an Octocat smiling and raising a tentacle.](https://github.com/chanyanhon/Demo-bug-report-generator/blob/main/screencap/eg1_post.png?raw=true)

### Example 2

Before tools

![Screenshot of a comment on a GitHub issue showing an image, added in the Markdown, of an Octocat smiling and raising a tentacle.](https://github.com/chanyanhon/Demo-bug-report-generator/blob/main/screencap/eg2_pre.png?raw=true)

After tools

![Screenshot of a comment on a GitHub issue showing an image, added in the Markdown, of an Octocat smiling and raising a tentacle.](https://github.com/chanyanhon/Demo-bug-report-generator/blob/main/screencap/eg2_post.png?raw=true)

### Example 3

Before tools

![Screenshot of a comment on a GitHub issue showing an image, added in the Markdown, of an Octocat smiling and raising a tentacle.](https://github.com/chanyanhon/Demo-bug-report-generator/blob/main/screencap/eg3_pre.png?raw=true)

After tools

![Screenshot of a comment on a GitHub issue showing an image, added in the Markdown, of an Octocat smiling and raising a tentacle.](https://github.com/chanyanhon/Demo-bug-report-generator/blob/main/screencap/eg3_post.png?raw=true)

### Example 4

Before tools

![Screenshot of a comment on a GitHub issue showing an image, added in the Markdown, of an Octocat smiling and raising a tentacle.](https://github.com/chanyanhon/Demo-bug-report-generator/blob/main/screencap/eg4_pre.png?raw=true)

After tools

![Screenshot of a comment on a GitHub issue showing an image, added in the Markdown, of an Octocat smiling and raising a tentacle.](https://github.com/chanyanhon/Demo-bug-report-generator/blob/main/screencap/eg4_post.png?raw=true)
